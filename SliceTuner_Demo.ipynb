{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from water_filling import Waterfilling\n",
    "from uniform import Uniform\n",
    "from slice_tuner import SliceTuner\n",
    "from cnn import CNN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Fashion-MNIST dataset from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of slices : 10\n"
     ]
    }
   ],
   "source": [
    "def shuffle(data, label):\n",
    "    shuffle = np.arange(len(data))\n",
    "    np.random.shuffle(shuffle)\n",
    "    data = data[shuffle]\n",
    "    label = label[shuffle]\n",
    "    return data, label\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "num_class = len(np.unique(train_labels))\n",
    "print(\"Number of slices : %d\" % num_class)\n",
    "\n",
    "y_train_one_hot = to_categorical(train_labels)\n",
    "fashion_data = (train_images, y_train_one_hot)\n",
    "\n",
    "initial_data_array = []\n",
    "val_data_dict = []\n",
    "add_data_dict = []\n",
    "    \n",
    "val_data_num = 500\n",
    "\n",
    "for i in range(num_class):\n",
    "    data_num = int(800 / (num_class - i) ** 0.5)\n",
    "    initial_data_array.append(data_num)\n",
    "    idx = np.argmax(fashion_data[1], axis=1) == i\n",
    "    \n",
    "    val_data_dict.append((fashion_data[0][idx][data_num:data_num+val_data_num], fashion_data[1][idx][data_num:data_num+val_data_num]))\n",
    "    add_data_dict.append((fashion_data[0][idx][data_num+val_data_num:], fashion_data[1][idx][data_num+val_data_num:]))\n",
    "    \n",
    "    if i == 0:\n",
    "        train_data = fashion_data[0][idx][:data_num]\n",
    "        train_label = fashion_data[1][idx][:data_num]\n",
    "        val_data = fashion_data[0][idx][data_num:data_num+val_data_num]\n",
    "        val_label = fashion_data[1][idx][data_num:data_num+val_data_num]\n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, fashion_data[0][idx][:data_num]), axis=0)\n",
    "        train_label = np.concatenate((train_label, fashion_data[1][idx][:data_num]), axis=0) \n",
    "        val_data = np.concatenate((val_data, fashion_data[0][idx][data_num:data_num+val_data_num]), axis=0)\n",
    "        val_label = np.concatenate((val_label, fashion_data[1][idx][data_num:data_num+val_data_num]), axis=0)\n",
    "    \n",
    "train_data, train_label = shuffle(train_data, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice: T-shirt/top, Number of data: 252\n",
      "Slice: Trouser, Number of data: 266\n",
      "Slice: Pullover, Number of data: 282\n",
      "Slice: Dress, Number of data: 302\n",
      "Slice: Coat, Number of data: 326\n",
      "Slice: Sandal, Number of data: 357\n",
      "Slice: Shirt, Number of data: 400\n",
      "Slice: Sneaker, Number of data: 461\n",
      "Slice: Bag, Number of data: 565\n",
      "Slice: Ankle boot, Number of data: 800\n"
     ]
    }
   ],
   "source": [
    "slice_desc = []\n",
    "a = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "for i in range(num_class):\n",
    "    slice_desc.append('Slice: %s, Number of data: %d' % (a[i], initial_data_array[i]))\n",
    "    print(slice_desc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SliceTuner Demo on Fashion-MNIST\n",
    "## Use 4000 budget, lambda=1, \"aggressive\" strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 623, 1046, 1470, 1893, 2317, 2740, 3164, 3587, 4011]\n",
      "======= Collect Data =======\n",
      "[633 183 700 430 670 269 908 137  68   0]\n",
      "Total Cost: 3998, Remaining Budget: 2\n",
      "======= Collect Data =======\n",
      "[2 0 0 0 0 0 0 0 0 0]\n",
      "Total Cost: 2, Remaining Budget: 0\n",
      "======= Performance =======\n",
      "Strategy: aggressive, C: 0.1, Budget: 4000\n",
      "Loss: 0.51788, Average EER: 0.33658, Max EER: 0.69904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st = SliceTuner((train_data, train_label), (val_data, val_label), val_data_dict, \n",
    "                initial_data_array, num_class, add_data_dict)\n",
    "\n",
    "cost_func = [1] * num_class\n",
    "st.selective_collect(budget=4000, k=10, cost_func=cost_func, Lambda=0.1, num_iter=10, \n",
    "                     slice_desc=slice_desc, strategy=\"aggressive\", show_figure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Uniform, Budget: 4000\n",
      "======= Collect Data =======\n",
      "[400 400 400 400 400 400 400 400 400 400]\n",
      "======= Performance =======\n",
      "[0.6525058686733246, 0.26227460205554964, 0.8486474454402924, 0.48090615570545203, 0.8235934257507326, 0.28539880514144894, 1.419605380296707, 0.29103708863258365, 0.26104407459497453, 0.14815770834684372]\n",
      "Loss: 0.54732, Average EER: 0.43197, Max EER: 0.96921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uni = Uniform((train_data, train_label), (val_data, val_label), val_data_dict, \n",
    "                initial_data_array, num_class, add_data_dict)\n",
    "\n",
    "cost_func = [1] * num_class\n",
    "uni.performance(budget=4000, cost_func=cost_func, num_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Water filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Water filling, Budget: 4000\n",
      "======= Collect Data =======\n",
      "[550 535 519 499 475 444 401 340 236   1]\n",
      "======= Performance =======\n",
      "[0.5863466978073121, 0.26531174778938293, 0.8590988457202913, 0.4644279211759567, 0.8195414245128632, 0.25585255622863773, 1.3708500146865843, 0.30778094604611395, 0.26048298478126525, 0.17388643324375153]\n",
      "Loss: 0.53636, Average EER: 0.41400, Max EER: 0.92721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wf = Waterfilling((train_data, train_label), (val_data, val_label), val_data_dict, \n",
    "                initial_data_array, num_class, add_data_dict)\n",
    "cost_func = [1] * num_class\n",
    "wf.performance(budget=4000, cost_func=cost_func, num_iter=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
